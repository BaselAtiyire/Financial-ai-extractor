{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b19ba724-b0fb-4847-81fa-de0a56957d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Neil Armstrong became the first person to set foot on the Moon, specifically on' additional_kwargs={} response_metadata={'model': 'llama3.2:1b', 'created_at': '2026-02-05T06:01:07.0289534Z', 'done': True, 'done_reason': 'length', 'total_duration': 820241900, 'load_duration': 285394500, 'prompt_eval_count': 34, 'prompt_eval_duration': 48433300, 'eval_count': 15, 'eval_duration': 399863900, 'logprobs': None, 'model_name': 'llama3.2:1b', 'model_provider': 'ollama'} id='lc_run--019c2c63-d59f-79c0-ace8-704298cfa06e-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 34, 'output_tokens': 15, 'total_tokens': 49}\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2:1b\", temperature=1.8, num_predict=15)\n",
    "print(llm.invoke(\"The first person to go to the moon was\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1185864f-b99b-4be4-9351-85bebdb8f8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52c4dd69-e247-4081-a326-2f63ee181b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basil\\OneDrive\\Desktop\\ai-projects\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e70e39fd-9c48-4403-866c-ad1b232452c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basil\\OneDrive\\Desktop\\ai-projects\n",
      "['.env', '.ipynb_checkpoints', 'Untitled.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "print(os.listdir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08db0b7e-c663-421d-ba20-43f8951b481e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key loaded: True\n",
      "Key preview: gsk_yp\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\", override=True)\n",
    "\n",
    "import os\n",
    "print(\"Key loaded:\", os.getenv(\"GROQ_API_KEY\") is not None)\n",
    "print(\"Key preview:\", os.getenv(\"GROQ_API_KEY\")[:6] if os.getenv(\"GROQ_API_KEY\") else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9861ec9c-3f1c-4fea-8e1f-507957488b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama-3.3-70b-versatile\", temperature=0.7)\n",
    "print(llm.invoke(\"Say hello in one word.\").content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7156fc5c-9cab-4fba-af5e-fb1feb46496f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming in Large Language Models (LLMs) refers to the process of continuously processing and generating text in real-time, as the user interacts with the model, without having to wait for the entire response to be generated and then returned. This technique allows for more efficient and dynamic conversations, enabling the model to adapt and respond to changing contexts and user input as it is received."
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\", streaming=True)\n",
    "\n",
    "for chunk in llm.stream(\"Explain streaming in LLMs in two sentences.\"):\n",
    "    print(chunk.content, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "768bc72c-e5ff-42a2-8d1d-4c3b5c3b216c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning LangChain: Unlocking the Power of AI Conversations\n",
      "\n",
      "Imagine having a super-smart assistant that can help you with anything from writing code to creating art. That's basically what LangChain is all about - a powerful tool that lets you build conversational AI models that can understand and respond to your needs.\n",
      "\n",
      "LangChain is a Python library that makes it easy to create, train, and deploy conversational AI models. It's like a LEGO set for building AI conversations, where you can snap together different blocks to create a customized chatbot that fits your needs.\n",
      "\n",
      "With LangChain, you can:\n",
      "\n",
      "1. **Ask questions and get answers**: LangChain lets you create conversational models that can understand natural language and respond with accurate answers.\n",
      "2. **Generate text and code**: You can use LangChain to generate text, code, and even entire documents based on your input.\n",
      "3. **Create chatbots and virtual assistants**: LangChain makes it easy to build chatbots that can help with customer support, scheduling, and more.\n",
      "4. **Experiment with AI**: LangChain provides a flexible platform for experimenting with different AI models and techniques, so you can learn and improve your skills.\n",
      "\n",
      "Learning LangChain is like learning a new language - it takes practice, but the more you use it, the more powerful you'll become. Here are some tips to get you started:\n",
      "\n",
      "1. **Start with the basics**: Learn the fundamentals of LangChain, including how to create and train conversational models.\n",
      "2. **Experiment and play**: Try out different LangChain features and see what you can create.\n",
      "3. **Join the community**: Connect with other LangChain users and learn from their experiences.\n",
      "4. **Practice, practice, practice**: The more you use LangChain, the more comfortable you'll become with its features and capabilities.\n",
      "\n",
      "So, are you ready to unlock the power of LangChain and start building your own conversational AI models? Let's get started!\n",
      "Summarize the topic of Retrieval Augmented Geneartion in simple style.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.3)\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Summarize the topic of {topic} in {style} style.\"\n",
    "\n",
    ")\n",
    "chain = prompt | llm\n",
    "\n",
    "print(chain.invoke({\"topic\": \"learning langchain\", \"style\": \"friendly\"}).content)\n",
    "\n",
    "\n",
    "#print(chain.invoke(\n",
    "\n",
    "#formatted_prompt = prompt.format(topic=\"Retrieval Augmented Geneartion\", style=\"simple\")\n",
    "print(formatted_prompt)\n",
    "\n",
    "#res = llm.invoke(formatted_prompt)\n",
    "#print(res.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "567855ee-8531-4a8f-b254-dd112b56e600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Learning LangChain: A Beginner's Journey**\n",
      "\n",
      "Hey everyone,\n",
      "\n",
      "As we continue to push the boundaries of conversational AI, I wanted to share my experience with LangChain - a powerful tool for building chatbots and conversational interfaces.\n",
      "\n",
      "For those who are new to LangChain, I'd like to offer some advice for getting started:\n",
      "\n",
      " **Start with the basics**: LangChain's documentation is comprehensive and easy to follow. Take your time to understand the fundamentals, including data structures, APIs, and core concepts.\n",
      "\n",
      " **Practice with examples**: LangChain's official repository has plenty of examples to help you get hands-on experience. Try modifying these examples to understand how LangChain works.\n",
      "\n",
      " **Join the community**: LangChain has an active community on GitHub, Reddit, and Stack Overflow. Don't hesitate to ask questions or share your projects.\n",
      "\n",
      " **Stay up-to-date**: LangChain is constantly evolving, so make sure to check the changelog and release notes regularly.\n",
      "\n",
      "I've learned a lot from my journey with LangChain, and I'm excited to see what you'll create!\n",
      "\n",
      "**Resources:**\n",
      "\n",
      "- LangChain Documentation: [link]\n",
      "- LangChain GitHub Repository: [link]\n",
      "- LangChain Community Forum: [link]\n",
      "\n",
      "**Let's build something amazing together!**\n",
      "\n",
      "Feel free to share your LangChain projects or ask questions in the comments below.\n",
      "\n",
      "Happy coding!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a {tone} LinkedIn post about {topic} for beginners.\"\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "print(chain.invoke({\"tone\": \"friendly\", \"topic\": \"learning LangChain\"}).content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0956b8d7-0e8c-4f20-bd7f-1db7dcf5201d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'John Doe', 'amount': 250, 'date': '2024-01-12'}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0)\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Extract structured information from the text below.\n",
    "\n",
    "Return ONLY valid JSON with these keys:\n",
    "- name (string)\n",
    "- amount (number)\n",
    "- date (string in YYYY-MM-DD format)\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "result = chain.invoke({\n",
    "    \"text\": \"John Doe paid $250 on 12th January 2024 for consulting services.\",\n",
    "    \"format_instructions\": parser.get_format_instructions()\n",
    "})\n",
    "\n",
    "print(result)\n",
    "print(type(result))  # dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b38538b9-4080-4056-b9c0-3a0e4a333b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'company': 'Apple', 'revenue': 143.756, 'period_end': 'December 31, 2025', 'yoy_growth_percent': 15.65}\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0)\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Extract financial information from the text.\n",
    "\n",
    "Return ONLY valid JSON with these keys:\n",
    "- company (string)\n",
    "- revenue (number)\n",
    "- period_end (string)\n",
    "- yoy_growth_percent (number)\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\").partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "result = chain.invoke({\n",
    "    \"text\": \"Apple revenue for the quarter ending December 31, 2025 was $143.756B, a 15.65% increase year-over-year.\"\n",
    "})\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a21b7d55-ebd9-4453-b2d7-1c574d2b2208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'company': 'Apple', 'records': [{'metric_type': 'quarter', 'period_end': '2025-12-31', 'year': None, 'revenue_billion_usd': 143.756, 'yoy_change_percent': 15.65, 'yoy_direction': 'increase'}, {'metric_type': 'twelve_months', 'period_end': '2025-12-31', 'year': None, 'revenue_billion_usd': 435.617, 'yoy_change_percent': 10.07, 'yoy_direction': 'increase'}, {'metric_type': 'annual', 'period_end': None, 'year': 2025, 'revenue_billion_usd': 416.161, 'yoy_change_percent': 6.43, 'yoy_direction': 'increase'}, {'metric_type': 'annual', 'period_end': None, 'year': 2024, 'revenue_billion_usd': 391.035, 'yoy_change_percent': 2.02, 'yoy_direction': 'increase'}, {'metric_type': 'annual', 'period_end': None, 'year': 2023, 'revenue_billion_usd': 383.285, 'yoy_change_percent': -2.8, 'yoy_direction': 'decline'}]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0)\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Extract ALL revenue records from the text.\n",
    "\n",
    "Return ONLY valid JSON in this format:\n",
    "{{\n",
    "  \"company\": \"Apple\",\n",
    "  \"records\": [\n",
    "    {{\n",
    "      \"metric_type\": \"quarter\" | \"twelve_months\" | \"annual\",\n",
    "      \"period_end\": \"YYYY-MM-DD\" | null,\n",
    "      \"year\": 2025 | null,\n",
    "      \"revenue_billion_usd\": number,\n",
    "      \"yoy_change_percent\": number,\n",
    "      \"yoy_direction\": \"increase\" | \"decline\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "- Convert revenue like $143.756B to revenue_billion_usd = 143.756\n",
    "- If a record is \"annual revenue for 2025\", set year=2025 and period_end=null\n",
    "- If a record has a date like \"December 31, 2025\", set period_end=\"2025-12-31\" and year=null\n",
    "- Include every line as one record.\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\").partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "text = \"\"\"Apple revenue for the quarter ending December 31, 2025 was $143.756B, a 15.65% increase year-over-year.\n",
    "Apple revenue for the twelve months ending December 31, 2025 was $435.617B, a 10.07% increase year-over-year.\n",
    "Apple annual revenue for 2025 was $416.161B, a 6.43% increase from 2024.\n",
    "Apple annual revenue for 2024 was $391.035B, a 2.02% increase from 2023.\n",
    "Apple annual revenue for 2023 was $383.285B, a 2.8% decline from 2022.\n",
    "\"\"\"\n",
    "\n",
    "result = chain.invoke({\"text\": text})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "35ecf744-b972-4d92-88ae-4e3c503b0161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"company\": \"Apple\",\n",
      "  \"records\": [\n",
      "    {\n",
      "      \"metric_type\": \"quarter\",\n",
      "      \"period_end\": \"2025-12-31\",\n",
      "      \"year\": null,\n",
      "      \"revenue_billion_usd\": 143.756,\n",
      "      \"yoy_change_percent\": 15.65,\n",
      "      \"yoy_direction\": \"increase\"\n",
      "    },\n",
      "    {\n",
      "      \"metric_type\": \"twelve_months\",\n",
      "      \"period_end\": \"2025-12-31\",\n",
      "      \"year\": null,\n",
      "      \"revenue_billion_usd\": 435.617,\n",
      "      \"yoy_change_percent\": 10.07,\n",
      "      \"yoy_direction\": \"increase\"\n",
      "    },\n",
      "    {\n",
      "      \"metric_type\": \"annual\",\n",
      "      \"period_end\": null,\n",
      "      \"year\": 2025,\n",
      "      \"revenue_billion_usd\": 416.161,\n",
      "      \"yoy_change_percent\": 6.43,\n",
      "      \"yoy_direction\": \"increase\"\n",
      "    },\n",
      "    {\n",
      "      \"metric_type\": \"annual\",\n",
      "      \"period_end\": null,\n",
      "      \"year\": 2024,\n",
      "      \"revenue_billion_usd\": 391.035,\n",
      "      \"yoy_change_percent\": 2.02,\n",
      "      \"yoy_direction\": \"increase\"\n",
      "    },\n",
      "    {\n",
      "      \"metric_type\": \"annual\",\n",
      "      \"period_end\": null,\n",
      "      \"year\": 2023,\n",
      "      \"revenue_billion_usd\": 383.285,\n",
      "      \"yoy_change_percent\": -2.8,\n",
      "      \"yoy_direction\": \"decline\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Saved to apple_revenue.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# 1) Load environment variables (.env with GROQ_API_KEY)\n",
    "load_dotenv()\n",
    "\n",
    "# 2) Initialize LLM (Groq)\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0)\n",
    "\n",
    "# 3) JSON output parser\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# 4) Prompt template\n",
    "# IMPORTANT: Any literal { } in the prompt must be escaped as {{ }}\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Extract ALL revenue records from the text.\n",
    "\n",
    "Return ONLY valid JSON in this format:\n",
    "{{\n",
    "  \"company\": \"Apple\",\n",
    "  \"records\": [\n",
    "    {{\n",
    "      \"metric_type\": \"quarter\" | \"twelve_months\" | \"annual\",\n",
    "      \"period_end\": \"YYYY-MM-DD\" | null,\n",
    "      \"year\": 2025 | null,\n",
    "      \"revenue_billion_usd\": number,\n",
    "      \"yoy_change_percent\": number,\n",
    "      \"yoy_direction\": \"increase\" | \"decline\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "- Convert revenue like $143.756B to revenue_billion_usd = 143.756\n",
    "- If a record is \"annual revenue for 2025\", set year=2025 and period_end=null\n",
    "- If a record has a date like \"December 31, 2025\", set period_end=\"2025-12-31\" and year=null\n",
    "- Include every line as one record.\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\").partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "# 5) Build chain\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# 6) Input text (multi-line)\n",
    "text = \"\"\"Apple revenue for the quarter ending December 31, 2025 was $143.756B, a 15.65% increase year-over-year.\n",
    "Apple revenue for the twelve months ending December 31, 2025 was $435.617B, a 10.07% increase year-over-year.\n",
    "Apple annual revenue for 2025 was $416.161B, a 6.43% increase from 2024.\n",
    "Apple annual revenue for 2024 was $391.035B, a 2.02% increase from 2023.\n",
    "Apple annual revenue for 2023 was $383.285B, a 2.8% decline from 2022.\n",
    "\"\"\"\n",
    "\n",
    "# 7) Invoke chain\n",
    "result = chain.invoke({\"text\": text})\n",
    "\n",
    "# 8) Print as REAL JSON text\n",
    "print(json.dumps(result, indent=2))\n",
    "\n",
    "# 9) Save to file (optional)\n",
    "with open(\"apple_revenue.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(result, f, indent=2)\n",
    "\n",
    "print(\"\\nSaved to apple_revenue.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "978c07f7-f741-45f7-b0bf-80618656dc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"company\": \"Apple\",\n",
      "  \"records\": [\n",
      "    {\n",
      "      \"metric_type\": \"quarter\",\n",
      "      \"period_end\": \"2025-12-31\",\n",
      "      \"year\": null,\n",
      "      \"revenue_billion_usd\": 143.756,\n",
      "      \"yoy_change_percent\": 15.65,\n",
      "      \"yoy_direction\": \"increase\"\n",
      "    },\n",
      "    {\n",
      "      \"metric_type\": \"twelve_months\",\n",
      "      \"period_end\": \"2025-12-31\",\n",
      "      \"year\": null,\n",
      "      \"revenue_billion_usd\": 435.617,\n",
      "      \"yoy_change_percent\": 10.07,\n",
      "      \"yoy_direction\": \"increase\"\n",
      "    },\n",
      "    {\n",
      "      \"metric_type\": \"annual\",\n",
      "      \"period_end\": null,\n",
      "      \"year\": 2025,\n",
      "      \"revenue_billion_usd\": 416.161,\n",
      "      \"yoy_change_percent\": 6.43,\n",
      "      \"yoy_direction\": \"increase\"\n",
      "    },\n",
      "    {\n",
      "      \"metric_type\": \"annual\",\n",
      "      \"period_end\": null,\n",
      "      \"year\": 2024,\n",
      "      \"revenue_billion_usd\": 391.035,\n",
      "      \"yoy_change_percent\": 2.02,\n",
      "      \"yoy_direction\": \"increase\"\n",
      "    },\n",
      "    {\n",
      "      \"metric_type\": \"annual\",\n",
      "      \"period_end\": null,\n",
      "      \"year\": 2023,\n",
      "      \"revenue_billion_usd\": 383.285,\n",
      "      \"yoy_change_percent\": -2.8,\n",
      "      \"yoy_direction\": \"decline\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def extract_financials(text: str) -> dict:\n",
    "    return chain.invoke({\"text\": text})\n",
    "\n",
    "result = extract_financials(text)\n",
    "print(json.dumps(result, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dd47ef07-e0ee-41e2-850e-34b7939175fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\basil\\anaconda3\\lib\\site-packages (1.37.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from streamlit) (5.0.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from streamlit) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from streamlit) (5.3.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from streamlit) (24.1)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from streamlit) (10.4.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from streamlit) (4.25.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from streamlit) (16.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from streamlit) (13.7.1)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from streamlit) (8.2.3)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from streamlit) (4.15.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from streamlit) (0.8.0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: watchdog<5,>=2.1.5 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from streamlit) (4.0.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\basil\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\basil\\anaconda3\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.15.1)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\basil\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8cf5e0f0-fc7d-4f0e-9543-a3d5816f6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import streamlit as st\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# Load GROQ_API_KEY from .env\n",
    "load_dotenv()\n",
    "\n",
    "# LLM + Parser\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0)\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# IMPORTANT: escape literal braces {{ }}\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a financial data extraction assistant.\n",
    "\n",
    "Extract ALL company financial metric statements from the text and return ONLY valid JSON\n",
    "in the following format:\n",
    "\n",
    "{{\n",
    "  \"company\": string | null,\n",
    "  \"currency\": \"USD\" | \"EUR\" | \"GBP\" | \"unknown\",\n",
    "  \"records\": [\n",
    "    {{\n",
    "      \"metric\": \"revenue\" | \"net_income\" | \"operating_income\" | \"eps\" | \"free_cash_flow\" | \"unknown\",\n",
    "      \"period_type\": \"quarter\" | \"ttm\" | \"annual\" | \"unknown\",\n",
    "      \"period_end\": \"YYYY-MM-DD\" | null,\n",
    "      \"fiscal_year\": number | null,\n",
    "      \"value\": number,\n",
    "      \"unit\": \"B\" | \"M\" | \"K\" | \"USD\" | \"unknown\",\n",
    "      \"yoy_change_percent\": number | null,\n",
    "      \"yoy_direction\": \"increase\" | \"decline\" | null,\n",
    "      \"source_text\": string\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "- If you see $143.756B, set value=143.756 and unit=\"B\" and currency=\"USD\"\n",
    "- If you see a date like \"December 31, 2025\", convert to \"2025-12-31\"\n",
    "- If yoy change is described like \"a 15.65% increase year-over-year\", set yoy_change_percent=15.65 and yoy_direction=\"increase\"\n",
    "- If yoy is \"decline\", set yoy_change_percent negative (e.g., -2.8)\n",
    "- Each statement/line should produce ONE record\n",
    "- Keep source_text as the exact line you extracted from\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\").partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# ---------- Streamlit UI ----------\n",
    "st.set_page_config(page_title=\"Financial Metrics Extractor\", layout=\"wide\")\n",
    "st.title(\"ðŸ“Š Financial Metrics Extractor (Text â†’ JSON)\")\n",
    "\n",
    "st.write(\"Paste company financial statements (revenue, YoY %, dates, annual/quarter/TTM). Click **Extract** to get JSON.\")\n",
    "\n",
    "default_text = \"\"\"Apple revenue for the quarter ending December 31, 2025 was $143.756B, a 15.65% increase year-over-year.\n",
    "Apple revenue for the twelve months ending December 31, 2025 was $435.617B, a 10.07% increase year-over-year.\n",
    "Apple annual revenue for 2025 was $416.161B, a 6.43% increase from 2024.\n",
    "Apple annual revenue for 2024 was $391.035B, a 2.02% increase from 2023.\n",
    "Apple annual revenue for 2023 was $383.285B, a 2.8% decline from 2022.\n",
    "\"\"\"\n",
    "\n",
    "text = st.text_area(\"Financial text\", value=default_text, height=220)\n",
    "\n",
    "col1, col2 = st.columns([1, 1])\n",
    "\n",
    "with col1:\n",
    "    if st.button(\"Extract\", type=\"primary\"):\n",
    "        if not text.strip():\n",
    "            st.warning(\"Please paste some financial text first.\")\n",
    "        else:\n",
    "            with st.spinner(\"Extracting...\"):\n",
    "                try:\n",
    "                    result = chain.invoke({\"text\": text})\n",
    "                    st.success(\"Done!\")\n",
    "                    st.subheader(\"JSON Output\")\n",
    "                    st.json(result)\n",
    "\n",
    "                    json_string = json.dumps(result, indent=2)\n",
    "                    st.download_button(\n",
    "                        label=\"Download JSON\",\n",
    "                        data=json_string,\n",
    "                        file_name=\"financial_metrics.json\",\n",
    "                        mime=\"application/json\",\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    st.error(\"Extraction failed.\")\n",
    "                    st.code(str(e))\n",
    "\n",
    "with col2:\n",
    "    st.subheader(\"Tips\")\n",
    "    st.markdown(\"\"\"\n",
    "- Works best with bullet points or one metric per line  \n",
    "- Add dates (quarter ending â€¦) to improve parsing  \n",
    "- Use temperature=0 for consistent JSON  \n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b2539c-ed12-406c-a88a-55eaecb1a3ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
